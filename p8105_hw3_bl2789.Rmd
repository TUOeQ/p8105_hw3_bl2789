---
title: "Homework 3"
author: "Bingkun Luo"
date: "10/10/2019"
output: github_document
---
# Problem 1
## a
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(p8105.datasets)
library(tidyverse)
library(data.table)
data("instacart")
str(instacart)
```

```{r}
aisle = instacart%>%
        group_by(aisle)%>%
        summarize(count=n()) %>%
        arrange(desc(count))

most = which.max(pull(aisle,count))

```

* There are **`r max(pull(instacart,aisle_id))`** aisles and the **`r aisle$aisle[most]`** are the most items ordered from.

## b
```{r}
aisle_10k = aisle %>%
            filter(count>10000) %>%
            arrange(desc(count))

ggplot(aisle_10k,aes(x = reorder(aisle,count), y = count))+
  geom_bar(stat="identity",fill="lightblue3" )+ 
  coord_flip()+
  labs(
    title = " Number of items ordered more than 10k",
    x = "Aisle name",
    y = "Items ordered most",
    caption = "Data from INSTACART")
```


## c
```{r}

pop_items = instacart %>% 
            filter(aisle == "baking ingredients"|aisle == "dog food care"|aisle ==                  "packaged vegetables fruits")%>%
            group_by(aisle,product_name)%>%
            summarize(n()) %>%
            top_n(3)
pop_items
```

## d 

```{r}
library(data.table)
Ordered_time_apple = instacart%>%
              filter(department == "produce")%>%
              filter(product_name %like% "Pink Lady")%>%
              group_by(order_dow) %>% 
              summarise(mean_hours = mean(order_hour_of_day)) %>% 
              mutate(product_name='Pink Lady Apple')%>%
              select(product_name,order_dow,mean_hours) 

Ordered_time_coffee = instacart%>%
              filter(aisle == "ice cream ice")%>%
              filter(product_name %like% "Coffee")%>%
              group_by(order_dow) %>% 
              summarise(mean_hours = mean(order_hour_of_day)) %>% 
              mutate(product_name='Coffee Ice Cream')%>%
              select(product_name,order_dow,mean_hours)

Order = rbind(Ordered_time_apple,Ordered_time_coffee)
pivot_wider(Order,names_from = order_dow,values_from = mean_hours)
  
```

# Problem 2
## Data cleaning 

```{r}
brfss_smart = brfss_smart2010%>%
                  janitor::clean_names()%>%
                  select(location_abbr = locationabbr,location_desc = locationdesc,   resp_id = respid,everything())%>%
                  filter(topic == "Overall Health")

my_levels = c("Excellent","Very good","Good","Fair","Poor")
response_adj = factor(pull(brfss_smart,response),levels = my_levels)
                  
brfss = brfss_smart%>%
        mutate(response_adj)%>%
        select(response_adj,everything(),-response)%>%
        arrange(desc(response_adj))

```

## a
```{r}
observed_2002 = brfss%>%
           filter(year == 2002)%>%
           group_by(location_abbr)%>%
           summarize(count=n())%>%
           filter(count/5>=7)%>%
           mutate(year = 2002)
  
observed_2010 = brfss%>%
           filter(year == 2010)%>%
           group_by(location_abbr)%>%
           summarize(count=n())%>%
           filter(count/5>=7)%>%
           mutate(year = 2010)
```
* In 2002,The states *`r pull(observed_2002,location_abbr)`* were observed at 7 or more locations. And in year 2010, *`r pull(observed_2010,location_abbr)`* were observed at 7 or more locations.

## b 
```{r}
subset = brfss%>%
         filter(response_adj == "Excellent")%>%
         select(year,location_abbr,data_value)%>%
         group_by(year,location_abbr)%>%
         mutate(average = mean(data_value))%>%
         select(-data_value)%>%
         distinct() 

ggplot(subset,aes(x=year,y=average,col=location_abbr))+ 
  geom_line(aes(group = location_abbr))
```

## c
```{r}
library(gridExtra)
NY_2006 = brfss%>%
          filter(year == 2006 & location_abbr == "NY")
plot_2006 = 
  ggplot(NY_2006,
         aes(x=response_adj, y = data_value,color = location_desc,group=location_desc))+
  geom_line()+
  labs(
    title = "Distribution of data_value for responses in 2006",
    x = "Response",
    y = "Data",
    caption = "Data from Newyork States")

NY_2010 = brfss%>%
          filter(year == 2010 & location_abbr == "NY")
plot_2010 = 
  ggplot(NY_2010,
         aes(x=response_adj, y = data_value,color=location_desc,group=location_desc))+
  geom_line()+
  labs(
    title = "Distribution of data_value for responses in 2010",
    x = "Response",
    y = "Data",
    caption = "Data from Newyork States")

grid.arrange(plot_2006, plot_2010, nrow = 2)
```

# Problem 3
## a
```{r}
accel_data = 
  read_csv(file = "./accel_data.csv")%>%
  janitor::clean_names()%>%
  mutate(weekday = ifelse(day %in% c("Monday", "Tuesday","Wednesday","Thursday","Friday"),1,0))%>%
  pivot_longer(activity_1:activity_1440,names_to = "minute",values_to = "activity_counts")%>%
  mutate(minute_number = as.integer(rep(c(1:1440),time = 35)))

```
* There are  `r nrow(accel_data)` observations and `r ncol(accel_data)` variables, including `r colnames(accel_data)`.

## b
```{r}

aggregate = accel_data%>%
          group_by(week,day_id,day) %>% 
          summarise(sum_of_day = sum(activity_counts))

my_levels = c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday")
day_adj = factor(pull(accel_data,day),levels = my_levels)

aggregate_day = accel_data%>%
                mutate(day_adj)%>%
                group_by(week,day_id,day_adj)%>% 
                summarise(sum_of_day = sum(activity_counts))%>%
                arrange(day_adj)
aggregate_day
ggplot(aggregate_day,aes(x=week,y=sum_of_day,fill = day_adj))+
  geom_bar(stat = "identity",position=position_dodge())+ 
  labs(
    title = "Distribution of total activity for each day",
    x = "days falls in weeks",
    y = "The total counts for one day",
    caption = "accel_data") 

  
        
```

